{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Урок 3. Парсинг данных. HTML, Beautiful Soap\n"
      ],
      "metadata": {
        "id": "ZYuuyGt18eDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Развернуть у себя на компьютере/виртуальной машине/хостинге MongoDB и реализовать функцию, которая будет добавлять только новые вакансии в вашу базу.\n",
        "2. Написать функцию, которая производит поиск и выводит на экран вакансии с заработной платой больше введённой суммы (необходимо анализировать оба поля зарплаты). Для тех, кто выполнил задание с Росконтролем - напишите запрос для поиска продуктов с рейтингом не ниже введенного или качеством не ниже введенного (то есть цифра вводится одна, а запрос проверяет оба поля)"
      ],
      "metadata": {
        "id": "95rKAxn7cEJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import certifi"
      ],
      "metadata": {
        "id": "Amb25GCXKSXA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fzw_AeOG8akV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pprint import pprint\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3V436Vh9zaS",
        "outputId": "07ac8226-a79c-4658-ff74-9df16e1e14df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.3.0 pymongo-4.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "from pymongo.errors import DuplicateKeyError"
      ],
      "metadata": {
        "id": "Rv8XPXnE9P6G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = MongoClient('127.0.0.1', 27017)\n",
        "db = client['HH_ru']\n",
        "jobs = db.jobs"
      ],
      "metadata": {
        "id": "RvtKILg_-ixD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://murmansk.hh.ru/'\n",
        "headers = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\",\n",
        "           \"Accept\": \"*/*\"}\n",
        "url = f'{base_url}/search/vacancy'"
      ],
      "metadata": {
        "id": "X9FBM4Th_syQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vacancy_list = []"
      ],
      "metadata": {
        "id": "rpKc2IwzARnG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zp_min = int(input('Zp min: '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SjZd8IrB509",
        "outputId": "f8581997-a54a-45b2-e5a9-cac1039e724a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zp min: 73000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1):\n",
        "\n",
        "  params = {'clusters' : 'true', 'area' : 1, 'ored_clusters' : 'true', 'enable_snippets' : 'true', 'salary' : '', 'st':'searchVacancy','text': 'pharma'}\n",
        "  params['page'] = int(i)\n",
        "  response = requests.get(url, headers=headers, params=params)\n",
        "  dom = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  vacancy = dom.find_all('div', {'class': 'vacancy-serp-item__layout'})\n",
        "\n",
        "  for items in vacancy:\n",
        "    vacancy_data = {}\n",
        "\n",
        "    info = items.find('a', {'class': 'serp-item__title'})\n",
        "    link = base_url + info['href']\n",
        "    name = info.getText()\n",
        "    company = items.find('a', {'class': 'bloko-link_kind-tertiary'}).getText()\n",
        "    views = items.find('div', {'class': 'online-users'})\n",
        "  \n",
        "    try:\n",
        "      salary = items.find('span', {'class': 'bloko-header-section-3'})\n",
        "  \n",
        "      if len(salary.split()) == 6:\n",
        "        min_salary = salary.split()[0] + salary.split()[1]\n",
        "        max_salary = salary.split()[3] + salary.split()[4]\n",
        "        valute = salary.split()[5]\n",
        "\n",
        "      elif len(salary.split()) == 4 and salary.split()[0] == 'от':\n",
        "        min_salary = salary.split()[1] + salary.split()[2]\n",
        "        max_salary = None\n",
        "        valute = salary.split()[3]\n",
        "\n",
        "\n",
        "      else:\n",
        "        min_salary = None\n",
        "        max_salary = salary.split()[1] + salary.split()[2]\n",
        "        valute = salary.split()[3]\n",
        "    except:\n",
        "      min_salary = None\n",
        "      max_salary = None\n",
        "      valute = None\n",
        "\n",
        "    vacancy_data['name'] = name\n",
        "    vacancy_data['link'] = link\n",
        "    vacancy_data['company'] = company\n",
        "    vacancy_data['views'] = views\n",
        "    try:\n",
        "      vacancy_data['min_salary'] = int(min_salary)\n",
        "      vacancy_data['max_salary'] = int(max_salary)\n",
        "      vacancy_data['valute'] = valute\n",
        "    except:\n",
        "      vacancy_data['min_salary'] = min_salary\n",
        "      vacancy_data['max_salary'] = max_salary\n",
        "      vacancy_data['valute'] = valute\n",
        "    \n",
        "    try:\n",
        "      if vacancy_data['min_salary'] >= zp_min or vacancy_data['max_salary'] >= zp_min:\n",
        "        pprint(vacancy_data)\n",
        "        print('\\n')\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    jobs.update_one({'link': vacancy_data['link']}, {'$set': vacancy_data}, upsert=True)\n",
        "\n",
        "\n",
        "f = 0\n",
        "for i in jobs.find({}):\n",
        "  f += 1\n"
      ],
      "metadata": {
        "id": "K37D72pGE9kz"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}